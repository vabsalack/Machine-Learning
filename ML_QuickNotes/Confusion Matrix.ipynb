{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30e4d68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7a4b808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function binomial:\n",
      "\n",
      "binomial(...) method of numpy.random.mtrand.RandomState instance\n",
      "    binomial(n, p, size=None)\n",
      "    \n",
      "    Draw samples from a binomial distribution.\n",
      "    \n",
      "    Samples are drawn from a binomial distribution with specified\n",
      "    parameters, n trials and p probability of success where\n",
      "    n an integer >= 0 and p is in the interval [0,1]. (n may be\n",
      "    input as a float, but it is truncated to an integer in use)\n",
      "    \n",
      "    .. note::\n",
      "        New code should use the ``binomial`` method of a ``default_rng()``\n",
      "        instance instead; please see the :ref:`random-quick-start`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    n : int or array_like of ints\n",
      "        Parameter of the distribution, >= 0. Floats are also accepted,\n",
      "        but they will be truncated to integers.\n",
      "    p : float or array_like of floats\n",
      "        Parameter of the distribution, >= 0 and <=1.\n",
      "    size : int or tuple of ints, optional\n",
      "        Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "        ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "        a single value is returned if ``n`` and ``p`` are both scalars.\n",
      "        Otherwise, ``np.broadcast(n, p).size`` samples are drawn.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray or scalar\n",
      "        Drawn samples from the parameterized binomial distribution, where\n",
      "        each sample is equal to the number of successes over the n trials.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    scipy.stats.binom : probability density function, distribution or\n",
      "        cumulative density function, etc.\n",
      "    Generator.binomial: which should be used for new code.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The probability density for the binomial distribution is\n",
      "    \n",
      "    .. math:: P(N) = \\binom{n}{N}p^N(1-p)^{n-N},\n",
      "    \n",
      "    where :math:`n` is the number of trials, :math:`p` is the probability\n",
      "    of success, and :math:`N` is the number of successes.\n",
      "    \n",
      "    When estimating the standard error of a proportion in a population by\n",
      "    using a random sample, the normal distribution works well unless the\n",
      "    product p*n <=5, where p = population proportion estimate, and n =\n",
      "    number of samples, in which case the binomial distribution is used\n",
      "    instead. For example, a sample of 15 people shows 4 who are left\n",
      "    handed, and 11 who are right handed. Then p = 4/15 = 27%. 0.27*15 = 4,\n",
      "    so the binomial distribution should be used in this case.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Dalgaard, Peter, \"Introductory Statistics with R\",\n",
      "           Springer-Verlag, 2002.\n",
      "    .. [2] Glantz, Stanton A. \"Primer of Biostatistics.\", McGraw-Hill,\n",
      "           Fifth Edition, 2002.\n",
      "    .. [3] Lentner, Marvin, \"Elementary Applied Statistics\", Bogden\n",
      "           and Quigley, 1972.\n",
      "    .. [4] Weisstein, Eric W. \"Binomial Distribution.\" From MathWorld--A\n",
      "           Wolfram Web Resource.\n",
      "           http://mathworld.wolfram.com/BinomialDistribution.html\n",
      "    .. [5] Wikipedia, \"Binomial distribution\",\n",
      "           https://en.wikipedia.org/wiki/Binomial_distribution\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Draw samples from the distribution:\n",
      "    \n",
      "    >>> n, p = 10, .5  # number of trials, probability of each trial\n",
      "    >>> s = np.random.binomial(n, p, 1000)\n",
      "    # result of flipping a coin 10 times, tested 1000 times.\n",
      "    \n",
      "    A real world example. A company drills 9 wild-cat oil exploration\n",
      "    wells, each with an estimated probability of success of 0.1. All nine\n",
      "    wells fail. What is the probability of that happening?\n",
      "    \n",
      "    Let's do 20,000 trials of the model, and count the number that\n",
      "    generate zero positive results.\n",
      "    \n",
      "    >>> sum(np.random.binomial(9, 0.1, 20000) == 0)/20000.\n",
      "    # answer = 0.38885, or 38%.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(numpy.random.binomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5820ff69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = numpy.random.binomial(1, 0.9, 1000)\n",
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "387d706b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = numpy.random.binomial(1, 0.9, 1000)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab503781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ececdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e3d5d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=[\"false\", \"true\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbb504d",
   "metadata": {},
   "source": [
    "The __Confusion Matrix__ created has four different quadrants:\n",
    "\n",
    "True Negative (Top-Left Quadrant)\n",
    "\n",
    "False Positive (Top-Right Quadrant)\n",
    "\n",
    "False Negative (Bottom-Left Quadrant)\n",
    "\n",
    "True Positive (Bottom-Right Quadrant)\n",
    "\n",
    "True means that the values were accurately predicted, False means that there was an error or wrong prediction.\n",
    "\n",
    "Now that we have made a Confusion Matrix, we can calculate different measures to quantify the quality of the model. First, lets look at Accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "669e09aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430bfa3e",
   "metadata": {},
   "source": [
    "The different measures include: Accuracy, Precision, Sensitivity (Recall), Specificity, and the F-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2228e118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.838"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (True Positive + True Negative) / Total Predictions\n",
    "\n",
    "Accuracy = metrics.accuracy_score(actual, predicted)\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "559e18d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9035087719298246"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Of the positives predicted, what percentage is truly positive?\n",
    "# True Positive / (True Positive + False Positive)\n",
    "\n",
    "Precision = metrics.precision_score(actual, predicted)\n",
    "Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4779334",
   "metadata": {},
   "source": [
    "__Sensitivity (Recall)__\n",
    "\n",
    "Of all the positive cases, what percentage are predicted positive?\n",
    "\n",
    "Sensitivity (sometimes called Recall) measures how good the model is at predicting positives.\n",
    "\n",
    "This means it looks at true positives and false negatives (which are positives that have been incorrectly predicted as negative).\n",
    "\n",
    "__True Positive / (True Positive + False Negative)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f4e08ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9175946547884187"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = metrics.recall_score(actual, predicted)\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b2fcb8",
   "metadata": {},
   "source": [
    "__Specificity__\n",
    "\n",
    "How well the model is at prediciting negative results?\n",
    "\n",
    "Specificity is similar to sensitivity, but looks at it from the persepctive of negative results.\n",
    "\n",
    "__True Negative / (True Negative + False Positive)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d57090a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13725490196078433"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specificity = metrics.recall_score(actual, predicted, pos_label=0)\n",
    "specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3afc3d",
   "metadata": {},
   "source": [
    "__F-score__\n",
    "\n",
    "F-score is the \"harmonic mean\" of precision and sensitivity.\n",
    "\n",
    "It considers both false positive and false negative cases and is good for imbalanced datasets.\n",
    "\n",
    "How to Calculate\n",
    "\n",
    "__2 * ((Precision * Sensitivity) / (Precision + Sensitivity))__\n",
    "\n",
    "This score does not take into consideration the True Negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8067e6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9104972375690609"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1score = metrics.f1_score(actual, predicted)\n",
    "f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112c8baf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
